{
  "providers": {
    "openai": {
      "api_key": "YOUR_OPENAI_API_KEY",
      "default_model": "gpt-4",
      "available_models": [
        {
          "id": "gpt-4",
          "max_tokens": 8192,
          "temperature_default": 0.7
        },
        {
          "id": "gpt-3.5-turbo",
          "max_tokens": 4096,
          "temperature_default": 0.7
        }
      ],
      "request_timeout": 30,
      "max_retries": 3
    },
    "anthropic": {
      "api_key": "YOUR_ANTHROPIC_API_KEY",
      "default_model": "claude-3-opus",
      "available_models": [
        {
          "id": "claude-3-opus",
          "max_tokens": 100000,
          "temperature_default": 0.7
        },
        {
          "id": "claude-3-sonnet",
          "max_tokens": 100000,
          "temperature_default": 0.7
        },
        {
          "id": "claude-3-haiku",
          "max_tokens": 100000,
          "temperature_default": 0.7
        }
      ],
      "request_timeout": 60,
      "max_retries": 2
    },
    "huggingface": {
      "api_key": "YOUR_HUGGINGFACE_API_KEY",
      "default_model": "mistralai/Mistral-7B-Instruct-v0.2",
      "available_models": [
        {
          "id": "mistralai/Mistral-7B-Instruct-v0.2",
          "max_tokens": 4096,
          "temperature_default": 0.7
        },
        {
          "id": "meta-llama/Llama-2-70b-chat-hf",
          "max_tokens": 4096,
          "temperature_default": 0.7
        }
      ],
      "inference_endpoint": "https://api-inference.huggingface.co/models/",
      "request_timeout": 60,
      "max_retries": 3
    }
  },
  "default_provider": "openai",
  "fallback_provider": "anthropic",
  "global_settings": {
    "max_input_length": 4000,
    "truncation_strategy": "end",
    "system_prompt": "You are a helpful assistant integrated with a chat platform. Provide concise and accurate responses."
  }
}